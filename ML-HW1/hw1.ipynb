{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **HW1: Regression** \n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement the regression model to predict the number of dengue cases\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# 1. Basic Part (60%)\n",
        "In the first part, you need to implement the regression to predict the number of dengue cases\n",
        "\n",
        "Please save the prediction result in a csv file **hw1_basic.csv**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "## Import Packages\n",
        "\n",
        "> Note: You **cannot** import any other package in the basic part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "## Global attributes\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n",
        "output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "input_datalist = [] # Initial datalist, saved as numpy array\n",
        "output_datalist = [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n",
        "             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFC-cvqIcYK"
      },
      "source": [
        "You can add your own global attributes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "deITlFQb31qV"
      },
      "outputs": [],
      "source": [
        "# Tag\n",
        "CityA = 1\n",
        "CityB = 2\n",
        "CityC = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": [
        "# Training dataset\n",
        "training_index = [3, 84]\n",
        "training_dataset = []\n",
        "\n",
        "# Validation dataset\n",
        "validation_index = [85, 94]\n",
        "validation_dataset = []\n",
        "\n",
        "# Testing dataset\n",
        "testing_index = [95, 104]\n",
        "testing_dataset = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gBDjHYSOpBes"
      },
      "outputs": [],
      "source": [
        "# Empty data: 02, 17, 37, 39, 83\n",
        "empty_set = [2, 17, 37, 39, 83]\n",
        "\n",
        "# Unreasonable data:\n",
        "# A: 7, 17, 21, 56, (84)\n",
        "invalid_A = [7, 17, 21, 56]\n",
        "# B: 27, 50, 76\n",
        "invalid_B = [27, 50, 76]\n",
        "# C: (1), 23, 36, 55, 72, (82)\n",
        "invalid_C = [23, 36, 55, 72]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t6ypwrgQ4X6I"
      },
      "outputs": [],
      "source": [
        "# Coefficient for regression model\n",
        "W = []\n",
        "MAPE = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "## Load the Input File\n",
        "First, load the basic input file **hw1_basic_input.csv**\n",
        "\n",
        "Input data would be stored in *input_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(input_dataroot, newline='') as csvfile:\n",
        "  input_datalist = np.array(list(csv.reader(csvfile)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "## Implement the Regression Model\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "### Step 1: Split Data\n",
        "Split data in *input_datalist* into training dataset and validation dataset \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def SplitData():\n",
        "  global empty_set, input_datalist\n",
        "  global training_dataset, validation_dataset, testing_dataset\n",
        "\n",
        "  # Handle null data\n",
        "  for i in empty_set:\n",
        "    input_datalist[i][1] = '0'\n",
        "    input_datalist[i][2] = '0'\n",
        "    input_datalist[i][3] = '0'\n",
        "\n",
        "  # Split training dataset and validation dataset\n",
        "  training_dataset = []\n",
        "  for i in range(training_index[0]-2, training_index[1]+1):\n",
        "    training_dataset.append(input_datalist[i])\n",
        " \n",
        "  validation_dataset = []\n",
        "  for i in range(validation_index[0]-2, validation_index[1]+1):\n",
        "    validation_dataset.append(input_datalist[i])\n",
        "\n",
        "  testing_dataset = []\n",
        "  for i in range(testing_index[0]-2, testing_index[1]+1):\n",
        "    testing_dataset.append(input_datalist[i])\n",
        "\n",
        "  training_dataset = np.array(training_dataset).astype(np.double)\n",
        "  validation_dataset = np.array(validation_dataset).astype(np.double)\n",
        "  testing_dataset = np.array(testing_dataset).astype(np.double)\n",
        "\n",
        "SplitData()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def PreprocessData():\n",
        "  global training_dataset, validation_dataset\n",
        "\n",
        "  # Handle missing data\n",
        "  for i in empty_set:\n",
        "    for j in range(1, 4):\n",
        "      training_dataset[i-1][j] = (training_dataset[i-1-1][j] + training_dataset[i-1+1][j]) / 2\n",
        "\n",
        "  # Handle unreasonable data\n",
        "  for i in invalid_A:\n",
        "    training_dataset[i-1][1] = (training_dataset[i-1-1][1] + training_dataset[i-1+1][1]) / 2\n",
        "  \n",
        "  for i in invalid_B:\n",
        "    training_dataset[i-1][2] = (training_dataset[i-1-1][2] + training_dataset[i-1+1][2]) / 2\n",
        "\n",
        "  for i in invalid_C:\n",
        "    training_dataset[i-1][3] = (training_dataset[i-1-1][3] + training_dataset[i-1+1][3]) / 2\n",
        "\n",
        "  # Special case\n",
        "  # A: 83, 84\n",
        "  training_dataset[83-1][1] = training_dataset[83-1-1][1]\n",
        "  training_dataset[84-1][1] = training_dataset[83-1-1][1]\n",
        "\n",
        "  # C: 1, 82, 83\n",
        "  training_dataset[1-1][3] = training_dataset[2-1][3]\n",
        "  training_dataset[82-1][3] = (training_dataset[84-1][3] + training_dataset[81-1][3]) / 2\n",
        "  training_dataset[83-1][3] = (training_dataset[84-1][3] + training_dataset[81-1][3]) / 2\n",
        "\n",
        "PreprocessData()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "### Step 3: Implement Regression\n",
        "> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "def Regression(tag): # A: tag = 1; B: tag = 2; C: tag = 3\n",
        "  Phi = []\n",
        "  Y = []\n",
        "\n",
        "  # Phi (1, X, X^2, Y(n-1), Y(n-2))\n",
        "  for i in range(2, len(training_dataset)):\n",
        "    Phi.append(np.array([1, training_dataset[i][tag], training_dataset[i-1][tag+3], training_dataset[i-2][tag+3]]))\n",
        "    Y.append(training_dataset[i][tag+3])\n",
        "  \n",
        "  Phi = np.array(Phi)\n",
        "  Y = np.array(Y)\n",
        "  Phi_t = Phi.transpose()\n",
        "\n",
        "  W = np.matmul(Phi_t, Phi)\n",
        "  W = np.linalg.inv(W)\n",
        "  W = np.matmul(W, Phi_t)\n",
        "  W = np.matmul(W, Y)\n",
        "\n",
        "  return W\n",
        "\n",
        "for i in range(1, 4):\n",
        "  W.append(Regression(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def MakePrediction(): # A: tag = 1; B: tag = 2; C: tag = 3\n",
        "  global testing_dataset\n",
        "\n",
        "  for i in range(2, len(testing_dataset)):\n",
        "    for tag in range(1, 4):\n",
        "      testing_dataset[i][tag+3] = W[tag-1][0] + W[tag-1][1] * testing_dataset[i][tag] + W[tag-1][2] * testing_dataset[i-1][tag+3] + W[tag-1][3] * testing_dataset[i-2][tag+3]\n",
        "\n",
        "MakePrediction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CqpoMxIv7DwW"
      },
      "outputs": [],
      "source": [
        "def Validation(tag):\n",
        "  # A: tag = 1\n",
        "  # B: tag = 2\n",
        "  # C: tag = 3\n",
        "  global validation_dataset\n",
        "\n",
        "  predict = []\n",
        "  for i in range(2, len(validation_dataset)): \n",
        "    predict.append(W[tag-1][0] + W[tag-1][1] * validation_dataset[i][tag] + W[tag-1][2] * validation_dataset[i-1][tag+3] + W[tag-1][3] * validation_dataset[i-2][tag+3])\n",
        "  predict = np.array(predict)\n",
        "\n",
        "  MAPE = 0\n",
        "  for i in range(2, len(validation_dataset)):\n",
        "    MAPE += abs((validation_dataset[i][tag+3] - predict[i-2]) / validation_dataset[i][tag+3])\n",
        "  MAPE /= len(validation_dataset) - 2\n",
        "\n",
        "  return MAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCEgbXkCd2Yf",
        "outputId": "26e7d34b-2b90-46f7-d331-f7637305708b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE for City A: 0.146862\n",
            "MAPE for City B: 0.224406\n",
            "MAPE for City C: 0.161006\n",
            "-----\n",
            "Average MAPE: 0.177425\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 4):\n",
        "  MAPE.append(Validation(i))\n",
        "\n",
        "print(\"MAPE for City A: %f\" % MAPE[CityA-1])\n",
        "print(\"MAPE for City B: %f\" % MAPE[CityB-1])\n",
        "print(\"MAPE for City C: %f\" % MAPE[CityC-1])\n",
        "print(\"-----\")\n",
        "print(\"Average MAPE: %f\" %((MAPE[CityA-1] + MAPE[CityB-1] + MAPE[CityC-1]) / 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCL92EPKOFIn",
        "outputId": "48f09539-2e5b-4258-933a-b6c4f6732709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regression model: Y_t = W_0 + W_1 * X_t + W_2 * X_t^2 + W_3 * Y_t-1 + W_4 * Y_t-2\n",
            "\n",
            "Coefficients for regression model of City A:\n",
            "23.342572396786203\t-0.7234345235786304\t0.6925538719235256\t0.18574610317073295\t\n",
            "\n",
            "Coefficients for regression model of City B:\n",
            "25.332426171345144\t-0.826650663174446\t0.4373583768396194\t0.3262980794417698\t\n",
            "\n",
            "Coefficients for regression model of City C:\n",
            "0.5821133183862983\t0.039517616080825574\t0.9069971855186248\t0.053177339810176125\t"
          ]
        }
      ],
      "source": [
        "print(\"Regression model: Y_t = W_0 + W_1 * X_t + W_2 * X_t^2 + W_3 * Y_t-1 + W_4 * Y_t-2\\n\")\n",
        "\n",
        "print(\"Coefficients for regression model of City A:\")\n",
        "for i in W[CityA-1]:\n",
        "  print(i, end = \"\\t\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Coefficients for regression model of City B:\")\n",
        "for i in W[CityB-1]:\n",
        "  print(i, end = \"\\t\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Coefficients for regression model of City C:\")\n",
        "for i in W[CityC-1]:\n",
        "  print(i, end = \"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "## Write the Output File\n",
        "Write the prediction to output csv\n",
        "> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "output_datalist = []\n",
        "for i in range(2, len(testing_dataset)):\n",
        "  output_datalist.append(np.array([int(testing_dataset[i][0]), testing_dataset[i][4], testing_dataset[i][5], testing_dataset[i][6]], dtype = '<U12'))\n",
        "\n",
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# 2. Advanced Part (35%)\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n",
        "\n",
        "We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n",
        "\n",
        "Please save the prediction result in a csv file **hw1_advanced.csv** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hwGUOnDkSZQ0"
      },
      "outputs": [],
      "source": [
        "advanced_input1_dataroot = 'hw1_advanced_input1.csv'\n",
        "advanced_input1_datalist = []\n",
        "\n",
        "advanced_input2_dataroot = 'hw1_advanced_input2.csv'\n",
        "advanced_input2_datalist = []\n",
        "\n",
        "advanced_output_dataroot = 'hw1_advanced.csv'\n",
        "advanced_output_datalist = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Coefficient for advanced regression model\n",
        "W_Advanced = []\n",
        "MAPE_Advanced = []\n",
        "\n",
        "num_of_factor = 0\n",
        "factor_set = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kf5LbrhmSScS"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(advanced_input1_dataroot, newline='') as csvfile:\n",
        "  advanced_input1_datalist = np.array(list(csv.reader(csvfile)))\n",
        "\n",
        "with open(advanced_input2_dataroot, newline='') as csvfile:\n",
        "  advanced_input2_datalist = np.array(list(csv.reader(csvfile)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cKpIwZqvWSiV"
      },
      "outputs": [],
      "source": [
        "advanced_factor1 = []\n",
        "for i in range(1, len(advanced_input1_datalist)):\n",
        "  advanced_factor1.append([advanced_input1_datalist[i][0], advanced_input1_datalist[i][1], advanced_input1_datalist[i][2], advanced_input1_datalist[i][3]])\n",
        "advanced_factor1 = np.array(advanced_factor1).astype(np.double)\n",
        "\n",
        "advanced_factor2 = []\n",
        "for i in range(1, 4):\n",
        "  tmp = []\n",
        "  for j in range(1, 26):\n",
        "    tmp.append(advanced_input2_datalist[i][j])\n",
        "  advanced_factor2.append(tmp)\n",
        "advanced_factor2 = np.array(advanced_factor2).astype(np.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DaZCe19m41g1"
      },
      "outputs": [],
      "source": [
        "def RegressionAdvanced(): \n",
        "  Phi = []\n",
        "  Y = []\n",
        "\n",
        "  # Phi (1, X, Y(n-1), Y(n-2), ...)\n",
        "  for i in range(2, len(training_dataset)):\n",
        "    for j in range(1, 4):\n",
        "      tmp = []\n",
        "      tmp.append(1); tmp.append(training_dataset[i][j])\n",
        "      tmp.append(training_dataset[i-1][j+3]); tmp.append(training_dataset[i-2][j+3]); tmp.append(advanced_factor1[i+training_index[0]-2-1][j])\n",
        "\n",
        "      for k in factor_set:\n",
        "        tmp.append(advanced_factor2[j-1][k])\n",
        "\n",
        "      Phi.append(np.array(tmp))\n",
        "      Y.append(training_dataset[i][j+3])\n",
        "  \n",
        "  Phi = np.array(Phi)\n",
        "  Y = np.array(Y)\n",
        "  Phi_t = Phi.transpose()\n",
        "\n",
        "  W = np.matmul(Phi_t, Phi)\n",
        "  W = np.linalg.inv(W)\n",
        "  W = np.matmul(W, Phi_t)\n",
        "  W = np.matmul(W, Y)\n",
        "\n",
        "  return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yDfPLb8adWkE"
      },
      "outputs": [],
      "source": [
        "def AdvancedValidation(printMAPE = False):\n",
        "  global validation_dataset\n",
        "\n",
        "  predict = []\n",
        "  for i in range(2, len(validation_dataset)):\n",
        "    tmp = []\n",
        "    for j in range(1, 4):\n",
        "      value = W_Advanced[0] + W_Advanced[1] * validation_dataset[i][j] + \\\n",
        "            W_Advanced[2] * validation_dataset[i-1][j+3] + W_Advanced[3] * validation_dataset[i-2][j+3] + W_Advanced[4] * advanced_factor1[i+validation_index[0]-2-1][j]\n",
        "\n",
        "      for k in range(num_of_factor):\n",
        "        value += W_Advanced[5+k] * advanced_factor2[j-1][factor_set[k]]\n",
        "\n",
        "      tmp.append(value)\n",
        "\n",
        "    predict.append(tmp)\n",
        "\n",
        "  predict = np.array(predict)\n",
        "\n",
        "  MAPE_A = 0\n",
        "  for i in range(2, len(validation_dataset)):\n",
        "    MAPE_A += abs((validation_dataset[i][4] - predict[i-2][0]) / validation_dataset[i][4])\n",
        "\n",
        "  MAPE_A /= len(validation_dataset) - 2\n",
        "\n",
        "  MAPE_B = 0\n",
        "  for i in range(2, len(validation_dataset)):\n",
        "    MAPE_B += abs((validation_dataset[i][5] - predict[i-2][1]) / validation_dataset[i][5])\n",
        "\n",
        "  MAPE_B /= len(validation_dataset) - 2\n",
        "\n",
        "  MAPE_C = 0\n",
        "  for i in range(2, len(validation_dataset)):\n",
        "    MAPE_C += abs((validation_dataset[i][6] - predict[i-2][2]) / validation_dataset[i][6])\n",
        "\n",
        "  MAPE_C /= len(validation_dataset) - 2\n",
        "\n",
        "  if printMAPE:\n",
        "    print(\"MAPE for City A: %f\" % MAPE_A)\n",
        "    print(\"MAPE for City B: %f\" % MAPE_B)\n",
        "    print(\"MAPE for City C: %f\" % MAPE_C)\n",
        "    print(\"-----\")\n",
        "    print(\"Average MAPE: %f\" %((MAPE_A + MAPE_B + MAPE_C) / 3))\n",
        "\n",
        "  return (MAPE_A + MAPE_B + MAPE_C) / 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeXmz1io_Otw",
        "outputId": "812b0ed4-e0d6-4cc2-ca6b-fe49b32b7a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regression model\n",
            "MAPE for City A: 0.143974\n",
            "MAPE for City B: 0.239281\n",
            "MAPE for City C: 0.134014\n",
            "-----\n",
            "Average MAPE: 0.172423\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "# Model with advanced_input1 only\n",
        "W_Advanced = RegressionAdvanced()\n",
        "MAPE_prev = AdvancedValidation()\n",
        "\n",
        "# Model with advanced_input1 and advanced_input2\n",
        "num_of_factor = 1\n",
        "factor_set = [0]\n",
        "\n",
        "W_Advanced = RegressionAdvanced()\n",
        "MAPE_prev = AdvancedValidation()\n",
        "\n",
        "for i in range(1, 25):\n",
        "  num_of_factor += 1\n",
        "  factor_set.append(i)\n",
        "\n",
        "  W_Advanced = RegressionAdvanced()\n",
        "\n",
        "  MAPE_curr = AdvancedValidation()\n",
        "\n",
        "  if MAPE_curr < MAPE_prev:\n",
        "    MAPE_prev = MAPE_curr\n",
        "  else:\n",
        "    num_of_factor -= 1\n",
        "    factor_set.pop()  \n",
        "\n",
        "\n",
        "print(\"Regression model\")  \n",
        "\n",
        "W_Advanced = RegressionAdvanced()\n",
        "MAPE_prev = AdvancedValidation(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzYPZho16cP",
        "outputId": "e4d4ea87-1a18-46b6-e410-f0c4ca13536c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Advanced regression model: Y_t = W_0 + W_1 * X_t + W_2 * Y_t-1 + W_3 * Y_t-2 + W_4 * Precipitation\n",
            " + W_5 * Population + W_6 * Age0-4(%) + W_7 * Age15-29(%) + W_8 * Peopledoinghousework(%)\n",
            "83.22373383723895\t-0.734040786536104\t0.686752431335002\t0.18762552098816643\t0.08068486948831305\t-3.431517918796645e-06\t-1.6811586299782215\t-1.9463103259693504\t0.3213397684964263\t"
          ]
        }
      ],
      "source": [
        "# Factor title\n",
        "factor_title = advanced_input2_datalist[0]\n",
        "\n",
        "print(\"Advanced regression model: Y_t = W_0 + W_1 * X_t + W_2 * Y_t-1 + W_3 * Y_t-2 + W_4 * Precipitation\")\n",
        "index = 5\n",
        "for i in factor_set:\n",
        "  print(\" + W_%d * %s\" % (index, factor_title[i+1]), end = '')\n",
        "  index += 1\n",
        "print()\n",
        "\n",
        "for i in W_Advanced:\n",
        "  print(i, end = '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rhe9y-tgbXb6"
      },
      "outputs": [],
      "source": [
        "def AdvancedMakePrediction():\n",
        "  global testing_dataset\n",
        "\n",
        "  for i in range(2, len(testing_dataset)):\n",
        "    for j in range(1, 4):\n",
        "      testing_dataset[i][j+3] = W_Advanced[0] + W_Advanced[1] * testing_dataset[i][j] + \\\n",
        "                      W_Advanced[2] * testing_dataset[i-1][j+3] + W_Advanced[3] * testing_dataset[i-2][j+3] + W_Advanced[4] * advanced_factor1[i+testing_index[0]-2-1][j]\n",
        "      for k in range(num_of_factor):\n",
        "          testing_dataset[i][j+3] += W_Advanced[5+k] * advanced_factor2[j-1][factor_set[k]]\n",
        "\n",
        "AdvancedMakePrediction()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kIRqxG1pyu-o"
      },
      "outputs": [],
      "source": [
        "advanced_output_datalist = []\n",
        "for i in range(2, len(testing_dataset)):\n",
        "  advanced_output_datalist.append(np.array([int(testing_dataset[i][0]), testing_dataset[i][4], testing_dataset[i][5], testing_dataset[i][6]], dtype = '<U12'))\n",
        "\n",
        "with open(advanced_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in advanced_output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgCJU7FPeJL"
      },
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered \n",
        "*   Summarize your work and your reflections \n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEE53_MPf4W"
      },
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1bacb2c8dfe2624014f653f6afeb0951fb975e73c62e9fdf6ac21449c87c2a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
